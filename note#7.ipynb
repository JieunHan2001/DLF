{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10df18d9",
   "metadata": {},
   "source": [
    "## 정리노트 #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95916931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0) # 시드값 고정\n",
    "x = np.random.rand(100,1)\n",
    "y = 5 + 2 * x + np.random.rand(100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f53a1",
   "metadata": {},
   "source": [
    "x로부터 실숫값 y를 예측하는 것을 **회귀**라고 한다. 그리고 회귀 모델 중 예측값이 선형(직선)을 이루는 것을 **선형 회귀**라고 한다. 선형 회귀는 손실 함수로 평균 제곱 오차를 이용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de67b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(current_dir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dezero import Variable\n",
    "import dezero.functions as F\n",
    "\n",
    "# 토이 데이터셋\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = 5 + 2 * x + np.random.rand(100, 1)\n",
    "x, y = Variable(x), Variable(y) # 생략 가능\n",
    "\n",
    "W = Variable(np.zeros((1, 1)))\n",
    "b = Variable(np.zeros(1))\n",
    "\n",
    "\n",
    "def predict(x):\n",
    "    y = F.matmul(x, W) + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98c4075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable([[0.64433458]]) variable([1.29473389]) variable(42.296340129442335)\n",
      "variable([[1.12672345]]) variable([2.26959351]) variable(23.97380754378544)\n",
      "variable([[1.48734571]]) variable([3.00386712]) variable(13.609686745040522)\n",
      "variable([[1.75641886]]) variable([3.557186]) variable(7.747049961219976)\n",
      "variable([[1.95666851]]) variable([3.97439789]) variable(4.43057410592155)\n",
      "variable([[2.10518573]]) variable([4.28923203]) variable(2.5542803813535926)\n",
      "variable([[2.21482401]]) variable([4.52705574]) variable(1.4925998690471942)\n",
      "variable([[2.29524981]]) variable([4.70694745]) variable(0.8916952181756932)\n",
      "variable([[2.35373273]]) variable([4.84325585]) variable(0.5514270962227453)\n",
      "variable([[2.39573972]]) variable([4.9467725]) variable(0.35859153083192785)\n",
      "variable([[2.425382]]) variable([5.02561369]) variable(0.2491573197756112)\n",
      "variable([[2.44575118]]) variable([5.08588371]) variable(0.18690658765397886)\n",
      "variable([[2.45917205]]) variable([5.13217364]) variable(0.15135336296314875)\n",
      "variable([[2.4673927]]) variable([5.16793652]) variable(0.13091003006317078)\n",
      "variable([[2.47172747]]) variable([5.19576949]) variable(0.11902210735018462)\n",
      "variable([[2.47316455]]) variable([5.21762597]) variable(0.11198198322254362)\n",
      "variable([[2.47244676]]) variable([5.23497527]) variable(0.10769231158094322)\n",
      "variable([[2.47013247]]) variable([5.24892259]) variable(0.10496655795675108)\n",
      "variable([[2.46664127]]) variable([5.26029927]) variable(0.10313337115761934)\n",
      "variable([[2.46228843]]) variable([5.26973075]) variable(0.10181280604960247)\n",
      "variable([[2.45731071]]) variable([5.27768752]) variable(0.10078974954301653)\n",
      "variable([[2.4518859]]) variable([5.28452363]) variable(0.09994232708821608)\n",
      "variable([[2.44614738]]) variable([5.29050548]) variable(0.09920140749444824)\n",
      "variable([[2.44019517]]) variable([5.29583359]) variable(0.09852769772358987)\n",
      "variable([[2.4341042]]) variable([5.30065891]) variable(0.09789878700703991)\n",
      "variable([[2.4279305]]) variable([5.30509512]) variable(0.09730181854646197)\n",
      "variable([[2.42171596]]) variable([5.30922787]) variable(0.0967293443169877)\n",
      "variable([[2.41549177]]) variable([5.3131217]) variable(0.09617698031441604)\n",
      "variable([[2.40928112]]) variable([5.31682532]) variable(0.09564208018092028)\n",
      "variable([[2.40310116]]) variable([5.32037549]) variable(0.09512298485383605)\n",
      "variable([[2.39696452]]) variable([5.3238]) variable(0.09461859803040694)\n",
      "variable([[2.39088043]]) variable([5.32711987]) variable(0.09412814592514404)\n",
      "variable([[2.38485555]]) variable([5.33035108]) variable(0.09365104127065577)\n",
      "variable([[2.37889464]]) variable([5.33350575]) variable(0.09318680628411545)\n",
      "variable([[2.37300101]]) variable([5.33659314]) variable(0.09273502898904006)\n",
      "variable([[2.3671769]]) variable([5.33962035]) variable(0.09229533840647547)\n",
      "variable([[2.36142374]]) variable([5.34259283]) variable(0.09186739042193233)\n",
      "variable([[2.35574235]]) variable([5.34551483]) variable(0.09145085969346782)\n",
      "variable([[2.35013309]]) variable([5.34838966]) variable(0.09104543497939387)\n",
      "variable([[2.34459602]]) variable([5.35121993]) variable(0.09065081640275062)\n",
      "variable([[2.33913091]]) variable([5.35400772]) variable(0.0902667138137311)\n",
      "variable([[2.33373736]]) variable([5.35675472]) variable(0.08989284577554084)\n",
      "variable([[2.32841486]]) variable([5.35946234]) variable(0.0895289389052284)\n",
      "variable([[2.32316275]]) variable([5.36213172]) variable(0.08917472741757472)\n",
      "variable([[2.31798034]]) variable([5.36476385]) variable(0.08882995278605695)\n",
      "variable([[2.31286689]]) variable([5.3673596]) variable(0.08849436347219049)\n",
      "variable([[2.30782159]]) variable([5.36991973]) variable(0.08816771469564999)\n",
      "variable([[2.30284363]]) variable([5.3724449]) variable(0.08784976822950144)\n",
      "variable([[2.29793221]]) variable([5.37493575]) variable(0.08754029221162851)\n",
      "variable([[2.29308646]]) variable([5.37739285]) variable(0.08723906096725743)\n",
      "variable([[2.28830557]]) variable([5.37981674]) variable(0.08694585483964615)\n",
      "variable([[2.2835887]]) variable([5.38220792]) variable(0.0866604600272269)\n",
      "variable([[2.278935]]) variable([5.38456689]) variable(0.08638266842618712)\n",
      "variable([[2.27434366]]) variable([5.38689411]) variable(0.0861122774778659)\n",
      "variable([[2.26981384]]) variable([5.38919004]) variable(0.08584909002056745)\n",
      "variable([[2.26534474]]) variable([5.39145512]) variable(0.08559291414552149)\n",
      "variable([[2.26093555]]) variable([5.39368978]) variable(0.08534356305679344)\n",
      "variable([[2.25658547]]) variable([5.39589443]) variable(0.08510085493499035)\n",
      "variable([[2.25229371]]) variable([5.39806949]) variable(0.08486461280463413)\n",
      "variable([[2.2480595]]) variable([5.40021536]) variable(0.08463466440508784)\n",
      "variable([[2.24388206]]) variable([5.40233244]) variable(0.08441084206493275)\n",
      "variable([[2.23976064]]) variable([5.40442111]) variable(0.08419298257969864)\n",
      "variable([[2.23569448]]) variable([5.40648177]) variable(0.08398092709285435)\n",
      "variable([[2.23168285]]) variable([5.40851479]) variable(0.08377452097997208)\n",
      "variable([[2.22772501]]) variable([5.41052054]) variable(0.08357361373597812)\n",
      "variable([[2.22382025]]) variable([5.41249938]) variable(0.08337805886540826)\n",
      "variable([[2.21996785]]) variable([5.41445169]) variable(0.08318771377558704)\n",
      "variable([[2.21616712]]) variable([5.41637782]) variable(0.08300243967265336)\n",
      "variable([[2.21241735]]) variable([5.41827811]) variable(0.08282210146035615)\n",
      "variable([[2.20871786]]) variable([5.42015291]) variable(0.08264656764154595)\n",
      "variable([[2.20506799]]) variable([5.42200258]) variable(0.08247571022229121)\n",
      "variable([[2.20146706]]) variable([5.42382744]) variable(0.08230940461854906)\n",
      "variable([[2.19791443]]) variable([5.42562782]) variable(0.08214752956532231)\n",
      "variable([[2.19440943]]) variable([5.42740407]) variable(0.08198996702823673)\n",
      "variable([[2.19095144]]) variable([5.42915649]) variable(0.08183660211747391)\n",
      "variable([[2.18753983]]) variable([5.43088541]) variable(0.08168732300399718)\n",
      "variable([[2.18417396]]) variable([5.43259114]) variable(0.08154202083800904)\n",
      "variable([[2.18085323]]) variable([5.434274]) variable(0.08140058966958151)\n",
      "variable([[2.17757703]]) variable([5.4359343]) variable(0.08126292637140048)\n",
      "variable([[2.17434477]]) variable([5.43757232]) variable(0.0811289305635685)\n",
      "variable([[2.17115586]]) variable([5.43918838]) variable(0.08099850454041051)\n",
      "variable([[2.16800971]]) variable([5.44078277]) variable(0.0808715531992303)\n",
      "variable([[2.16490575]]) variable([5.44235578]) variable(0.08074798397096412)\n",
      "variable([[2.16184341]]) variable([5.44390769]) variable(0.08062770675268231)\n",
      "variable([[2.15882214]]) variable([5.44543879]) variable(0.08051063384188899)\n",
      "variable([[2.15584139]]) variable([5.44694936]) variable(0.08039667987257197)\n",
      "variable([[2.15290062]]) variable([5.44843967]) variable(0.08028576175295649)\n",
      "variable([[2.14999928]]) variable([5.44990999]) variable(0.08017779860491725)\n",
      "variable([[2.14713684]]) variable([5.4513606]) variable(0.08007271170500452)\n",
      "variable([[2.1443128]]) variable([5.45279175]) variable(0.07997042442704135)\n",
      "variable([[2.14152662]]) variable([5.45420371]) variable(0.07987086218625004)\n",
      "variable([[2.13877781]]) variable([5.45559674]) variable(0.07977395238486742)\n",
      "variable([[2.13606587]]) variable([5.45697108]) variable(0.07967962435920853)\n",
      "variable([[2.13339029]]) variable([5.458327]) variable(0.07958780932814088)\n",
      "variable([[2.13075059]]) variable([5.45966473]) variable(0.07949844034293135)\n",
      "variable([[2.12814629]]) variable([5.46098452]) variable(0.07941145223842926)\n",
      "variable([[2.12557692]]) variable([5.46228661]) variable(0.07932678158554966)\n",
      "variable([[2.123042]]) variable([5.46357124]) variable(0.07924436664502324)\n",
      "variable([[2.12054108]]) variable([5.46483864]) variable(0.07916414732237737)\n",
      "variable([[2.11807369]]) variable([5.46608905]) variable(0.07908606512411756)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 평균 제곱 오차 \n",
    "def mean_squared_error(x0, x1):\n",
    "    diff = x0 - x1\n",
    "    return F.sum(diff ** 2) / len(diff)\n",
    "\n",
    "# 경사 하강법을 사용하여 100회 반복으로 훈련을 수행\n",
    "lr = 0.1\n",
    "iters = 100\n",
    "\n",
    "# 각 반복에서 손실을 계산하고, 역전파를 수행하여 그라디언트를 얻은 다음, 학습률을 사용하여 가중치와 편향을 업데이트\n",
    "for i in range(iters):\n",
    "    y_pred = predict(x)\n",
    "    loss = mean_squared_error(y, y_pred)\n",
    "\n",
    "    W.cleargrad()\n",
    "    b.cleargrad()\n",
    "    loss.backward()\n",
    "\n",
    "    W.data -= lr * W.grad.data # 매개변수를 갱신할 때 인스턴수 변수의 data에 대해 계산해야 함\n",
    "    b.data -= lr * b.grad.data\n",
    "    print(W, b, loss)\n",
    "\n",
    "\n",
    "# 그래프\n",
    "plt.scatter(x.data, y.data, s=10)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "y_pred = predict(x)\n",
    "plt.plot(x.data, y_pred.data, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6005ff0d",
   "metadata": {},
   "source": [
    "### 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb728f4",
   "metadata": {},
   "source": [
    "$y = F.matmul(x,W) + b$<br>\n",
    "입력 x와 매개변수 W 사이에서 행렬 곱을 구하고, 거기에 b를 더하는 것을 **선형 변환** 또는 **아핀 변환**이라고 한다.<br>\n",
    "선형 변환은 신경망에서 **완전연결계층**에 해당하며, 매개변수 **W**는 **가중치**, 매개변수 **b**는 **편향**이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41fcdcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_simple(x, W, b=None):\n",
    "    t = matmul(x, W)\n",
    "    if b is None:\n",
    "        return t\n",
    "\n",
    "    y = t + b\n",
    "    t.data = None # t의 데이터는 역전파 시 필요치 않으므로 메모리에서 삭제\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71baff17",
   "metadata": {},
   "source": [
    "비선형 데이터셋은 선형 회귀로는 풀 수가 없고, 신경망으로 해결해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ab25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비선형 데이터셋\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = np.sin(2 * np.pi * x) + np.random.rand(100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf81eec",
   "metadata": {},
   "source": [
    "신경망은 선형 변환의 출력에 비선형 변환을 수행하는데, 이 비선형 변환을 **활성화 함수**라고 하며 대표적으로 **ReLU 함수**와 **시그모이드** 함수가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54162b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 함수\n",
    "\n",
    "def sigmoid_simple(x):\n",
    "    x = as_variable(x)\n",
    "    y = 1 / (1 + exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccec8d9",
   "metadata": {},
   "source": [
    "신경망은 일반적으로 선형 변환과 활성화 함수를 순서대로 적용하는데, 이것이 신경망 추론 코드이다. 이 추론을 제대로 하려면 학습이 필요하고, 신경망 학습에서는 추론을 처리한 후 손실 함수를 추가하고, 손실 함수의 출력을 최소화하는 매개변수를 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d7b337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.8473695850105871)\n",
      "variable(0.2514286285183606)\n",
      "variable(0.2475948546674987)\n",
      "variable(0.23786120447054812)\n",
      "variable(0.21222231333102912)\n",
      "variable(0.16742181117834118)\n",
      "variable(0.09681932619992623)\n",
      "variable(0.07849528290602323)\n",
      "variable(0.07749729552991155)\n",
      "variable(0.07722132399559312)\n"
     ]
    }
   ],
   "source": [
    "# 신경망 학습 코드\n",
    "\n",
    "# 데이터셋\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = np.sin(2 * np.pi * x) + np.random.rand(100, 1)\n",
    "\n",
    "# 가중치 초기화\n",
    "I, H, O = 1, 10, 1  # I, H, O는 입력층, 은닉층, 출력층의 노드 수\n",
    "# 첫 번째 및 두 번째 선형 계층의 가중치와 편향을 나타내는 변수\n",
    "W1 = Variable(0.01 * np.random.randn(I, H))\n",
    "b1 = Variable(np.zeros(H))\n",
    "W2 = Variable(0.01 * np.random.randn(H, O))\n",
    "b2 = Variable(np.zeros(O))\n",
    "\n",
    "# 신경망 추론\n",
    "# 입력 x를 첫 번째 선형 계층을 통해 처리하고, 활성화 함수(시그모이드)를 적용한 후 두 번째 선형 계층으로 전달\n",
    "def predict(x):\n",
    "    y = F.linear(x, W1, b1)\n",
    "    y = F.sigmoid(y)\n",
    "    y = F.linear(y, W2, b2)\n",
    "    return y\n",
    "\n",
    "\n",
    "lr = 0.2\n",
    "iters = 10000\n",
    "\n",
    "for i in range(iters):\n",
    "    y_pred = predict(x) # 각 반복에서 예측값을 계산하고, 실제값과의 평균 제곱 오차를 구함\n",
    "    loss = F.mean_squared_error(y, y_pred)\n",
    "\n",
    "    W1.cleargrad()\n",
    "    b1.cleargrad()\n",
    "    W2.cleargrad()\n",
    "    b2.cleargrad()\n",
    "    loss.backward()\n",
    "\n",
    "    W1.data -= lr * W1.grad.data\n",
    "    b1.data -= lr * b1.grad.data\n",
    "    W2.data -= lr * W2.grad.data\n",
    "    b2.data -= lr * b2.grad.data\n",
    "    if i % 1000 == 0: # 각 반복(iteration)의 인덱스 i가 1000의 배수일 때마다, 즉 0, 1000, 2000, ..., 9000번째 반복에서 손실 값을 출력\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff6eaa",
   "metadata": {},
   "source": [
    "### 매개변수를 모아두는 계층\n",
    "\n",
    "매개변수는 경사하강법 등의 최적화 기법에 의해 갱신되는 변수이다. 예를 들어 선형 변환에 사용되는 **가중치**와 **편향**이 매개변수에 해당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c55fc55",
   "metadata": {},
   "source": [
    "Parameter 클래스는 Variable 클래스와 똑같은 기능을 갖게 한다.\n",
    "```python\n",
    "class Parameter(Variable):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca015a34",
   "metadata": {},
   "source": [
    "layer 클래스는 기반 클래스로 두고 구체적인 변환은 자식 클래스에서 구현한다.\n",
    "```python\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self._params = set() # _params라는 인스턴스 변스에 Layer 인스턴스에 속한 매개변수를 보관한다.\n",
    "\n",
    "    def __setattr__(self, name, value): # 인스턴스 변수를 설정할 때 호출되는 특수 메서드\n",
    "        if isinstance(value, Parameter: #  value가 Parameter 인스턴스인지 확인\n",
    "            self._params.add(name)\n",
    "        super().__setattr__(name, value) # 실제 속성 설정은 상위 클래스의 __setattr__ 메서드를 통해 처리되도록 함\n",
    "                      \n",
    "    def __call__(self, *inputs): \n",
    "        outputs = self.forward(*inputs)\n",
    "        if not isinstance(outputs, tuple):\n",
    "            outputs = (outputs,)\n",
    "        self.inputs = [weakref.ref(x) for x in inputs]\n",
    "        self.outputs = [weakref.ref(y) for y in outputs]\n",
    "        return outputs if len(outputs) > 1 else outputs[0]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def params(self): \n",
    "        for name in self._params:  # _params 집합에 포함된 각 이름에 대해 해당 객체를 가져옴\n",
    "            obj = self.__dict__[name]\n",
    "\n",
    "            if isinstance(obj, Layer): # 만약 이 객체가 다른 Layer 객체라면 재귀적으로 그 레이어의 params 메서드를 호출\n",
    "                yield from obj.params()\n",
    "            else:\n",
    "                yield obj # 그렇지 않으면 파라미터 객체를 반환\n",
    "\n",
    "    def cleargrads(self):\n",
    "        for param in self.params():\n",
    "            param.cleargrad()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5184ba54",
   "metadata": {},
   "source": [
    "개선된 버전의 Linear 클래스 구현\n",
    "```python\n",
    "class Linear(Layer):\n",
    "    def __init__(self, out_size, nobias=False, dtype=np.float32, in_size=None):\n",
    "        super().__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.W = Parameter(None, name='W')\n",
    "        if self.in_size is not None:\n",
    "            self._init_W()\n",
    "\n",
    "        if nobias:\n",
    "            self.b = None\n",
    "        else:\n",
    "            self.b = Parameter(np.zeros(out_size, dtype=dtype), name='b')\n",
    "\n",
    "    def _init_W(self, xp=np):\n",
    "        I, O = self.in_size, self.out_size\n",
    "        # 가중치는 정규 분포에서 샘플링한 후, np.sqrt(1 / I)로 스케일링하여 초기화\n",
    "        W_data = xp.random.randn(I, O).astype(self.dtype) * np.sqrt(1 / I)\n",
    "        self.W.data = W_data\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 데이터를 흘려보내는 시점에 가중치 초기화\n",
    "        if self.W.data is None:\n",
    "            self.in_size = x.shape[1]\n",
    "            self._init_W()\n",
    "\n",
    "        y = F.linear(x, self.W, self.b)\n",
    "        return y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9caec194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.8165178492839196)\n",
      "variable(0.24990280802148895)\n",
      "variable(0.24609876581126014)\n",
      "variable(0.23721590814318072)\n",
      "variable(0.20793216413350174)\n",
      "variable(0.12311905720649353)\n",
      "variable(0.07888166506355153)\n",
      "variable(0.07655073683421634)\n",
      "variable(0.07637803086238225)\n",
      "variable(0.0761876413118557)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = np.sin(2 * np.pi * x) + np.random.rand(100, 1)\n",
    "\n",
    "l1 = L.Linear(10) # 출력 크기 지정\n",
    "l2 = L.Linear(1) \n",
    "\n",
    "\n",
    "def predict(x):\n",
    "    y = l1(x)\n",
    "    y = F.sigmoid(y)\n",
    "    y = l2(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "lr = 0.2\n",
    "iters = 10000\n",
    "\n",
    "for i in range(iters):\n",
    "    y_pred = predict(x)\n",
    "    loss = F.mean_squared_error(y, y_pred)\n",
    "\n",
    "    l1.cleargrads()\n",
    "    l2.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    for l in [l1, l2]: #  두 개의 레이어 l1과 l2에 대한 파라미터를 업데이트\n",
    "        for p in l.params(): \n",
    "            # 기울기의 방향으로 파라미터 값을 조정하여 손실 함수를 최소화\n",
    "            p.data -= lr * p.grad.data # p.data는 파라미터의 현재 값이며, p.grad.data는 해당 파라미터의 기울기\n",
    "    if i % 1000 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a360babc",
   "metadata": {},
   "source": [
    "위 코드에서 매개변수 관리를 Linear 인스턴스가 맡고 있다는 점이 중요하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9df564",
   "metadata": {},
   "source": [
    "현재 Layer 클래스는 여러 개의 Parameter를 가질 수 있다. 여기에 더해 Layer 클래스가 **다른 Layer**도 담을 수 있게 확장한다.<br>\n",
    "```python\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self._params = set()\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, (Parameter, Layer)): # Layer도 추가\n",
    "            self._params.add(name)\n",
    "        super().__setattr__(name, value)\n",
    "\n",
    "    def params(self):\n",
    "        for name in self._params:\n",
    "            obj = self.__dict__[name]\n",
    "\n",
    "            if isinstance(obj, Layer): # Layer에서 매개변수 꺼내기\n",
    "                yield from obj.params()\n",
    "            else:\n",
    "                yield obj\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c935e",
   "metadata": {},
   "source": [
    "yield를 사용한 함수를 제너레이터라고 한다. 제너레이터를 사용하여 또 다른 제너레이터를 만들고자 할 때는 yield from을 사용한다. \n",
    "제너레이터는 일반적인 함수와 달리, 함수의 실행을 일시 중지하고 값을 반환(yield)할 수 있으며, 다음 번 호출 시에 일시 중지된 부분부터 실행을 재개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2521b84",
   "metadata": {},
   "source": [
    "```python\n",
    "# Layer 클래스를 더 편리하게 사용하기 위해 Layer 클래스를 상속하여 모델 전체를 하나의 클래스로 정의할 수 있다.\n",
    "\n",
    "class TwoLayerNet(Layer):\n",
    "    def __init__(self, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        self.l1 = L.Linear(hidden_size)\n",
    "        self.l2 = L.Linear(out_size)\n",
    "    def forward(self, x):\n",
    "        y = F.sigmoid(self.l1(x))\n",
    "        y = self.l2(y)\n",
    "        return y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6716ed8",
   "metadata": {},
   "source": [
    "복잡한 패턴이나 규칙이 숨어 있는 현상을 수식을 사용하여 단순하게 표현한 것을 **모델**이라고 한다.\n",
    "\n",
    "```python\n",
    "from dezero import Layer\n",
    "from dezero import utils\n",
    "\n",
    "\n",
    "class Model(Layer):\n",
    "    def plot(self, *inputs, to_file='model.png'): \n",
    "        y = self.forward(*inputs)\n",
    "        return utils.plot_dot_graph(y, verbose=True, to_file=to_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72868313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.8165178492839196)\n",
      "variable(0.24990280802148895)\n",
      "variable(0.24609876581126014)\n",
      "variable(0.23721590814318072)\n",
      "variable(0.20793216413350174)\n",
      "variable(0.12311905720649353)\n",
      "variable(0.07888166506355153)\n",
      "variable(0.07655073683421634)\n",
      "variable(0.07637803086238225)\n",
      "variable(0.0761876413118557)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(current_dir)\n",
    "import numpy as np\n",
    "from dezero import Model\n",
    "import dezero.layers as L\n",
    "import dezero.functions as F\n",
    "\n",
    "# 데이터셋 생성\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = np.sin(2 * np.pi * x) + np.random.rand(100, 1)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "lr = 0.2 # 학습률\n",
    "max_iter = 10000 # 훈련을 위한 반복 횟수\n",
    "hidden_size = 10  # 은닉층의 뉴런 수\n",
    "\n",
    "# 모델 정의 \n",
    "class TwoLayerNet(Model):\n",
    "    def __init__(self, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        self.l1 = L.Linear(hidden_size) # hidden_size는 첫 번째 (은닉) 레이어의 뉴런 수를 나타냄\n",
    "        self.l2 = L.Linear(out_size) # out_size는 두 번째 레이어(출력 레이어)의 뉴런 수를 나타냄\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.sigmoid(self.l1(x))\n",
    "        y = self.l2(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "model = TwoLayerNet(hidden_size, 1)\n",
    "\n",
    "# 학습 시작\n",
    "for i in range(max_iter):\n",
    "    y_pred = model(x)\n",
    "    loss = F.mean_squared_error(y, y_pred)\n",
    "\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    for p in model.params():\n",
    "        p.data -= lr * p.grad.data\n",
    "    if i % 1000 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7febe1",
   "metadata": {},
   "source": [
    "```python\n",
    "# 완전연결계층 신경망 구현\n",
    "class MLP(Model):\n",
    "    def __init__(self, fc_output_sizes, activation=F.sigmoid):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.layers = []\n",
    "\n",
    "        for i, out_size in enumerate(fc_output_sizes):\n",
    "            layer = L.Linear(out_size)\n",
    "            setattr(self, 'l' + str(i), layer)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.layers[:-1]:\n",
    "            x = self.activation(l(x))\n",
    "        return self.layers[-1](x)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
